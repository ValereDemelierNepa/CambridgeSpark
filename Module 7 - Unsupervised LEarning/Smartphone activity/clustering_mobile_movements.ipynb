{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Clustering mobile user movements\n","\n","Modern cell phones have powerful in-build sensors that allow tracking the physical movements of its user. From the data delivered by the accelerometer we can try to infer the underlying activity, such as walking or standing. Many useful applications can use this information, for instance fitness tracking or adaptive notifications.\n","\n","In this exercise the task is to infer underlying movements of the user by grouping similar movement using unsupervised techniques. Apart from a small subset, the training samples are not labeled. In the end you may test if your groups correspond to the held out ground-truth activities. \n","\n","This task has two key challenges. **Extracting useful features** that are useful for classifying the activities, and implementing **effective clustering methods**. The task has these broad steps:\n","1. Load and visualize data\n","3. Extract features\n","3. Clustering methods\n","4. Validate clusters\n","\n","Feel free to optimize your methods in each step and use all you have learned to improve your performance. Also feel free to reorganize your pipeline to make running the all steps at once easier, for instance with `sklearn.pipeline`."]},{"cell_type":"markdown","metadata":{},"source":["KATE expects your code to define variables with specific names that correspond to certain things we are interested in.\n","\n","KATE will run your notebook from top to bottom and check the latest value of those variables, so make sure you don't overwrite them.\n","\n","* Remember to uncomment the line assigning the variable to your answer and don't change the variable or function names.\n","* Use copies of the original or previous DataFrames to make sure you do not overwrite them by mistake.\n","\n","You will find instructions below about how to define each variable.\n","\n","Once you're happy with your code, upload your notebook to KATE to check your feedback."]},{"cell_type":"markdown","metadata":{},"source":["### Load the data"]},{"cell_type":"markdown","metadata":{},"source":["#### About the data\n","\n","The experiments have been carried out with a group of volunteers performing six activities (WALKING, WALKINGUPSTAIRS, WALKINGDOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone on the waist ([video](https://www.youtube.com/watch?v=XOEN9W05_4A)). Using its embedded accelerometer and gyroscope, 3-axial linear acceleration, body acceleration and angular velocity were collected.\n","\n","For more info, the reference paper: [Domain Dataset for Human Activity Recognition Using Smartphones](https://scholar.google.com/scholar?q=a+public+domain+dataset+for+human+activity+recognition+using+smartphones&hl=en&as_sdt=0&as_vis=1&oi=scholart).\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Import the relevant libraries"]},{"cell_type":"code","execution_count":164,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{},"source":["#### Import the data files"]},{"cell_type":"markdown","metadata":{},"source":["Each data file has an array of times series, with X, Y and Z directions each."]},{"cell_type":"code","execution_count":165,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(7352, 128)\n"]}],"source":["body_acc_x_train = np.loadtxt(\"data/body_acc_x_train.txt\")\n","body_acc_y_train = np.loadtxt(\"data/body_acc_y_train.txt\")\n","body_acc_z_train = np.loadtxt(\"data/body_acc_z_train.txt\")\n","\n","body_gyro_x_train = np.loadtxt(\"data/body_gyro_x_train.txt\")\n","body_gyro_y_train = np.loadtxt(\"data/body_gyro_y_train.txt\")\n","body_gyro_z_train = np.loadtxt(\"data/body_gyro_z_train.txt\")\n","\n","total_acc_x_train = np.loadtxt(\"data/total_acc_x_train.txt\")\n","total_acc_y_train = np.loadtxt(\"data/total_acc_y_train.txt\")\n","total_acc_z_train = np.loadtxt(\"data/total_acc_z_train.txt\")\n","\n","print(body_acc_x_train.shape)"]},{"cell_type":"markdown","metadata":{},"source":["#### We can join the time series into a single raw dataset."]},{"cell_type":"code","execution_count":166,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(7352, 1152)\n"]}],"source":["X_train = np.array(np.hstack([body_acc_x_train, body_acc_y_train, body_acc_z_train,\n","                   body_gyro_x_train, body_gyro_y_train, body_gyro_z_train,\n","                   total_acc_x_train, total_acc_y_train, total_acc_z_train]))\n","\n","print(X_train.shape)"]},{"cell_type":"markdown","metadata":{},"source":["#### Load the labels for the first 200 samples of the data. \n","\n","The labels indicate:\n","1. WALKING\n","2. WALKING_UPSTAIRS\n","3. WALKING_DOWNSTAIRS\n","4. SITTING\n","5. STANDING\n","6. LAYING"]},{"cell_type":"code","execution_count":167,"metadata":{},"outputs":[],"source":["y_train = np.loadtxt(\"data/y_train.txt\")"]},{"cell_type":"markdown","metadata":{},"source":["Print the the number of samples in each category. Is the data set balanced?"]},{"cell_type":"code","execution_count":168,"metadata":{"scrolled":true},"outputs":[{"data":{"text/plain":["Labels\n","5.0    44\n","1.0    36\n","4.0    31\n","6.0    31\n","3.0    30\n","2.0    28\n","Name: count, dtype: int64"]},"execution_count":168,"metadata":{},"output_type":"execute_result"}],"source":["y_train_df = pd.DataFrame({\"Labels\":y_train})\n","y_train_df.value_counts(\"Labels\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Visualize the trajectories"]},{"cell_type":"markdown","metadata":{},"source":["Inspect the time series data by plotting some (X,Y,Z) data samples over time."]},{"cell_type":"code","execution_count":169,"metadata":{},"outputs":[],"source":["feature_df = pd.DataFrame()"]},{"cell_type":"markdown","metadata":{},"source":["## Extract features"]},{"cell_type":"markdown","metadata":{},"source":["The raw time-series could be used directly as input to machine learning, but it might not be very effective. A key challenge is to extract features that could help identify and differentiate between activities. Feel free to select from or go beyond the suggestions and come up with your own features."]},{"cell_type":"markdown","metadata":{},"source":["### Time series properties\n","\n","* **Magnitude**: Calculate the magnitude of a 3-dimensional time series at each time point, given by the norm of the (X,Y,Z) vector: $$mag(t) = \\sqrt{acc_X^2(t) + acc_Y^2(t) + acc_Z^2(t)}$$\n","\n","* **Jerk**: Calculate the change in acceleration, known as jerk. You may calculate it by the different in acceleration over a time lag: $$jerk(t) = acc(t) - acc(t-lag)$$.\n","\n","* **Spectral properties**: Calculate the frequency domain analysis using FFT of a time-series.\n","\n","* **Autoregressive model**: Calculate the auto-regressive model for a time-series and use its parameters as features."]},{"cell_type":"markdown","metadata":{},"source":["# Valere Notes:\n","\n","The data consists of 7k rows and 128 cols (time series).\n","\n","The goal is to calculate measure from the times series. For example the body acceleration magnitude will return magnitude at each time series point. Then for our model we might be interestd in the mean, std, min, max of the magnitude, where each one of these will make up a feature in our model.\n","\n","Read above the labels correspond to the first 200 samples in the data."]},{"cell_type":"code","execution_count":170,"metadata":{},"outputs":[],"source":["body_acc_magnitude = np.sqrt(body_acc_x_train**2 + body_acc_y_train**2 + body_acc_z_train**2)\n","body_gyro_magnitude = np.sqrt(body_gyro_x_train**2 + body_gyro_y_train**2 + body_gyro_z_train**2)\n","total_acc_magnitude = np.sqrt(total_acc_x_train**2 + total_acc_y_train**2 + total_acc_z_train**2)"]},{"cell_type":"markdown","metadata":{},"source":["#### Join time series"]},{"cell_type":"code","execution_count":171,"metadata":{},"outputs":[],"source":["data_dict = {\n","    \"body_acc_x_train\": body_acc_x_train,\n","    \"body_acc_y_train\": body_acc_y_train,\n","    \"body_acc_z_train\": body_acc_z_train,\n","    \"body_gyro_x_train\": body_gyro_x_train,\n","    \"body_gyro_y_train\": body_gyro_y_train,\n","    \"body_gyro_z_train\": body_gyro_z_train,\n","    \"total_acc_x_train\": total_acc_x_train,\n","    \"total_acc_y_train\": total_acc_y_train,\n","    \"total_acc_z_train\": total_acc_z_train,\n","    \"body_acc_magnitude\": body_acc_magnitude,\n","    \"body_gyro_magnitude\": body_gyro_magnitude,\n","    \"total_acc_magnitude\": total_acc_magnitude\n","}"]},{"cell_type":"code","execution_count":172,"metadata":{},"outputs":[],"source":["# from statsmodels.tsa.ar_model import AutoReg\n","\n","# def calculate_ar_params(series, lag):\n","#     ar_params = []\n","#     for i in series:\n","#         model = AutoReg(i, lags=lag).fit()\n","#         ar_params.append(model.params)\n","#     return np.array(ar_params)\n","\n","# ar_dict = pd.DataFrame()\n","# for key, value in data_dict.items():\n","#     ar_params = calculate_ar_params(value, 1)\n","#     ar_params = pd.DataFrame(ar_params)\n","#     ar_params.columns = [key + \"_ar_1\", key + \"_ar_2\"]\n","#     ar_dict = pd.concat([ar_dict, ar_params], axis=1)\n","\n"]},{"cell_type":"code","execution_count":173,"metadata":{},"outputs":[],"source":["fft = {}\n","for key, value in data_dict.items():\n","    fft[key +\"FFT\"] = np.fft.fft(value)\n","\n","temp = {}\n","for key, value in fft.items():\n","    temp[key +\"_mean\"] = np.mean(value, axis = 1)\n","    temp[key +\"_std\"] = np.std(value, axis = 1)\n","    temp[key +\"_min\"] = np.min(value, axis = 1)\n","    temp[key +\"_max\"] = np.max(value, axis = 1)\n","    temp[key +\"_median\"] = np.median(value, axis = 1)\n","\n","fft_features = pd.DataFrame(temp)"]},{"cell_type":"markdown","metadata":{},"source":["### Statistical features\n","\n","* Design statistical features to extract from the time-series you have gathered, such as minimal/maximal value or standard deviation. Again, you can be creative on features that might be relevant to classify a time series, for instance the Median Absolute Deviation or the Signal Magnitude Area."]},{"cell_type":"code","execution_count":174,"metadata":{},"outputs":[],"source":["def IQR(dist, axis = 1):\n","    return np.percentile(dist, 75) - np.percentile(dist, 25)\n","\n","funcs = [np.min, np.std, np.mean, np.max, IQR]\n","\n","\n","for key, value in data_dict.items():\n","    for func in funcs:\n","        feature_df[key + \"_\" + func.__name__] = func(value, axis=1)"]},{"cell_type":"code","execution_count":175,"metadata":{},"outputs":[],"source":["X_train = pd.concat([feature_df, fft_features], axis = 1)"]},{"cell_type":"markdown","metadata":{},"source":["* Implement a function that estimate these statistical features for each time series and join them into a training dataset."]},{"cell_type":"markdown","metadata":{},"source":["How many features do you have in total?"]},{"cell_type":"code","execution_count":176,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(7352, 144)\n"]}],"source":["# How many features do you have in total?\n","print(X_train.shape)"]},{"cell_type":"markdown","metadata":{},"source":["## Clustering activities\n","\n","Now that you have defined your features, the second key challenge is to model your data with clustering algorithms, trying to group data sample of the same activity together."]},{"cell_type":"markdown","metadata":{},"source":["### Preprocess features\n","\n","Make sure to preprocess your data to be adequate as input to your algorithms."]},{"cell_type":"code","execution_count":177,"metadata":{},"outputs":[],"source":["\n","# Assuming X_train is your training data\n","if np.iscomplexobj(X_train):\n","    X_train = np.real(X_train)"]},{"cell_type":"code","execution_count":178,"metadata":{},"outputs":[],"source":["# ### Preprocess features\n","\n","# Make sure to preprocess your data to be adequate as input to your algorithms.\n","# Manual feautre scaling\n","from sklearn.preprocessing import StandardScaler\n","\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","\n","# def min_max_scale(series):\n","#     return (series - series.min()) / (series.max() - series.min())\n","\n","# X_train = X_train.apply(min_max_scale, axis = 0)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Clustering\n","\n","* Now is the time to implement the core clustering algorithm with the data you have preprocessed.\n","* You can use any algorithm you have learned. Remember to optimize its parameters for performance.\n","* Note that you can use the few available labels to extend or evaluate your model."]},{"cell_type":"code","execution_count":179,"metadata":{},"outputs":[{"data":{"text/html":["<style>#sk-container-id-2 {\n","  /* Definition of color scheme common for light and dark mode */\n","  --sklearn-color-text: black;\n","  --sklearn-color-line: gray;\n","  /* Definition of color scheme for unfitted estimators */\n","  --sklearn-color-unfitted-level-0: #fff5e6;\n","  --sklearn-color-unfitted-level-1: #f6e4d2;\n","  --sklearn-color-unfitted-level-2: #ffe0b3;\n","  --sklearn-color-unfitted-level-3: chocolate;\n","  /* Definition of color scheme for fitted estimators */\n","  --sklearn-color-fitted-level-0: #f0f8ff;\n","  --sklearn-color-fitted-level-1: #d4ebff;\n","  --sklearn-color-fitted-level-2: #b3dbfd;\n","  --sklearn-color-fitted-level-3: cornflowerblue;\n","\n","  /* Specific color for light theme */\n","  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n","  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-icon: #696969;\n","\n","  @media (prefers-color-scheme: dark) {\n","    /* Redefinition of color scheme for dark theme */\n","    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n","    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-icon: #878787;\n","  }\n","}\n","\n","#sk-container-id-2 {\n","  color: var(--sklearn-color-text);\n","}\n","\n","#sk-container-id-2 pre {\n","  padding: 0;\n","}\n","\n","#sk-container-id-2 input.sk-hidden--visually {\n","  border: 0;\n","  clip: rect(1px 1px 1px 1px);\n","  clip: rect(1px, 1px, 1px, 1px);\n","  height: 1px;\n","  margin: -1px;\n","  overflow: hidden;\n","  padding: 0;\n","  position: absolute;\n","  width: 1px;\n","}\n","\n","#sk-container-id-2 div.sk-dashed-wrapped {\n","  border: 1px dashed var(--sklearn-color-line);\n","  margin: 0 0.4em 0.5em 0.4em;\n","  box-sizing: border-box;\n","  padding-bottom: 0.4em;\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","#sk-container-id-2 div.sk-container {\n","  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n","     but bootstrap.min.css set `[hidden] { display: none !important; }`\n","     so we also need the `!important` here to be able to override the\n","     default hidden behavior on the sphinx rendered scikit-learn.org.\n","     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n","  display: inline-block !important;\n","  position: relative;\n","}\n","\n","#sk-container-id-2 div.sk-text-repr-fallback {\n","  display: none;\n","}\n","\n","div.sk-parallel-item,\n","div.sk-serial,\n","div.sk-item {\n","  /* draw centered vertical line to link estimators */\n","  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n","  background-size: 2px 100%;\n","  background-repeat: no-repeat;\n","  background-position: center center;\n","}\n","\n","/* Parallel-specific style estimator block */\n","\n","#sk-container-id-2 div.sk-parallel-item::after {\n","  content: \"\";\n","  width: 100%;\n","  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n","  flex-grow: 1;\n","}\n","\n","#sk-container-id-2 div.sk-parallel {\n","  display: flex;\n","  align-items: stretch;\n","  justify-content: center;\n","  background-color: var(--sklearn-color-background);\n","  position: relative;\n","}\n","\n","#sk-container-id-2 div.sk-parallel-item {\n","  display: flex;\n","  flex-direction: column;\n","}\n","\n","#sk-container-id-2 div.sk-parallel-item:first-child::after {\n","  align-self: flex-end;\n","  width: 50%;\n","}\n","\n","#sk-container-id-2 div.sk-parallel-item:last-child::after {\n","  align-self: flex-start;\n","  width: 50%;\n","}\n","\n","#sk-container-id-2 div.sk-parallel-item:only-child::after {\n","  width: 0;\n","}\n","\n","/* Serial-specific style estimator block */\n","\n","#sk-container-id-2 div.sk-serial {\n","  display: flex;\n","  flex-direction: column;\n","  align-items: center;\n","  background-color: var(--sklearn-color-background);\n","  padding-right: 1em;\n","  padding-left: 1em;\n","}\n","\n","\n","/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n","clickable and can be expanded/collapsed.\n","- Pipeline and ColumnTransformer use this feature and define the default style\n","- Estimators will overwrite some part of the style using the `sk-estimator` class\n","*/\n","\n","/* Pipeline and ColumnTransformer style (default) */\n","\n","#sk-container-id-2 div.sk-toggleable {\n","  /* Default theme specific background. It is overwritten whether we have a\n","  specific estimator or a Pipeline/ColumnTransformer */\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","/* Toggleable label */\n","#sk-container-id-2 label.sk-toggleable__label {\n","  cursor: pointer;\n","  display: block;\n","  width: 100%;\n","  margin-bottom: 0;\n","  padding: 0.5em;\n","  box-sizing: border-box;\n","  text-align: center;\n","}\n","\n","#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n","  /* Arrow on the left of the label */\n","  content: \"▸\";\n","  float: left;\n","  margin-right: 0.25em;\n","  color: var(--sklearn-color-icon);\n","}\n","\n","#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n","  color: var(--sklearn-color-text);\n","}\n","\n","/* Toggleable content - dropdown */\n","\n","#sk-container-id-2 div.sk-toggleable__content {\n","  max-height: 0;\n","  max-width: 0;\n","  overflow: hidden;\n","  text-align: left;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-2 div.sk-toggleable__content.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-2 div.sk-toggleable__content pre {\n","  margin: 0.2em;\n","  border-radius: 0.25em;\n","  color: var(--sklearn-color-text);\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n","  /* Expand drop-down */\n","  max-height: 200px;\n","  max-width: 100%;\n","  overflow: auto;\n","}\n","\n","#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n","  content: \"▾\";\n","}\n","\n","/* Pipeline/ColumnTransformer-specific style */\n","\n","#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator-specific style */\n","\n","/* Colorize estimator box */\n","#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n","#sk-container-id-2 div.sk-label label {\n","  /* The background is the default theme color */\n","  color: var(--sklearn-color-text-on-default-background);\n","}\n","\n","/* On hover, darken the color of the background */\n","#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","/* Label box, darken color on hover, fitted */\n","#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator label */\n","\n","#sk-container-id-2 div.sk-label label {\n","  font-family: monospace;\n","  font-weight: bold;\n","  display: inline-block;\n","  line-height: 1.2em;\n","}\n","\n","#sk-container-id-2 div.sk-label-container {\n","  text-align: center;\n","}\n","\n","/* Estimator-specific */\n","#sk-container-id-2 div.sk-estimator {\n","  font-family: monospace;\n","  border: 1px dotted var(--sklearn-color-border-box);\n","  border-radius: 0.25em;\n","  box-sizing: border-box;\n","  margin-bottom: 0.5em;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-2 div.sk-estimator.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","/* on hover */\n","#sk-container-id-2 div.sk-estimator:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-2 div.sk-estimator.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Specification for estimator info (e.g. \"i\" and \"?\") */\n","\n","/* Common style for \"i\" and \"?\" */\n","\n",".sk-estimator-doc-link,\n","a:link.sk-estimator-doc-link,\n","a:visited.sk-estimator-doc-link {\n","  float: right;\n","  font-size: smaller;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1em;\n","  height: 1em;\n","  width: 1em;\n","  text-decoration: none !important;\n","  margin-left: 1ex;\n","  /* unfitted */\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-unfitted-level-1);\n","}\n","\n",".sk-estimator-doc-link.fitted,\n","a:link.sk-estimator-doc-link.fitted,\n","a:visited.sk-estimator-doc-link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","/* Span, style for the box shown on hovering the info icon */\n",".sk-estimator-doc-link span {\n","  display: none;\n","  z-index: 9999;\n","  position: relative;\n","  font-weight: normal;\n","  right: .2ex;\n","  padding: .5ex;\n","  margin: .5ex;\n","  width: min-content;\n","  min-width: 20ex;\n","  max-width: 50ex;\n","  color: var(--sklearn-color-text);\n","  box-shadow: 2pt 2pt 4pt #999;\n","  /* unfitted */\n","  background: var(--sklearn-color-unfitted-level-0);\n","  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n","}\n","\n",".sk-estimator-doc-link.fitted span {\n","  /* fitted */\n","  background: var(--sklearn-color-fitted-level-0);\n","  border: var(--sklearn-color-fitted-level-3);\n","}\n","\n",".sk-estimator-doc-link:hover span {\n","  display: block;\n","}\n","\n","/* \"?\"-specific style due to the `<a>` HTML tag */\n","\n","#sk-container-id-2 a.estimator_doc_link {\n","  float: right;\n","  font-size: 1rem;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1rem;\n","  height: 1rem;\n","  width: 1rem;\n","  text-decoration: none;\n","  /* unfitted */\n","  color: var(--sklearn-color-unfitted-level-1);\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","}\n","\n","#sk-container-id-2 a.estimator_doc_link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","#sk-container-id-2 a.estimator_doc_link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","}\n","</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=6, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;KMeans<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.cluster.KMeans.html\">?<span>Documentation for KMeans</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>KMeans(n_clusters=6, random_state=42)</pre></div> </div></div></div></div>"],"text/plain":["KMeans(n_clusters=6, random_state=42)"]},"execution_count":179,"metadata":{},"output_type":"execute_result"}],"source":["# ## Clustering\n","\n","# * Now is the time to implement the core clustering algorithm with the data you have preprocessed.\n","# * You can use any algorithm you have learned. Remember to optimize its parameters for performance.\n","# * Note that you can use the few available labels to extend or evaluate your model.\n","\n","from sklearn.cluster import KMeans\n","\n","kmeans = KMeans(n_clusters=6, random_state=42)\n","kmeans.fit(X_train)"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluate your clusters"]},{"cell_type":"markdown","metadata":{},"source":["Now we can try to visualize how our samples were grouped. As usual, it's not simple to visualize high dimensional data, so we will focus on a couple of dimensions."]},{"cell_type":"markdown","metadata":{},"source":["### Visualize ground-truth groups"]},{"cell_type":"markdown","metadata":{},"source":["Plot a scatter plot of two features of your choice for all samples in a single colour. Overlay it with scatter plot of the labeled samples, coloring them by their label.\n","\n","Do the activities seem well separated? Which seem similar?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":180,"metadata":{"scrolled":false},"outputs":[],"source":["# import seaborn as sns\n","\n","# truth_df = pd.DataFrame(X_train[0:200])\n","\n","# sns.scatterplot(x = truth_df[0], y = truth_df[1], hue = y_train)"]},{"cell_type":"markdown","metadata":{},"source":["### Visualize your groups"]},{"cell_type":"markdown","metadata":{},"source":["Plot a scatter plot of two features of your choice for all samples, coloring them by their cluster.\n","\n","Do your cluster seem to correspond to the true activity clusters?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["Print the size of each cluster. Does it seem balanced? What does it mean?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["### Performance metrics"]},{"cell_type":"markdown","metadata":{},"source":["#### Confusion matrix"]},{"cell_type":"markdown","metadata":{},"source":["We can evaluate the clusters by checking if they can be mapped into activities for the labeled samples. One way to inspect this mapping is through the confusion matrix. \n","\n","Calculate and print the confusion matrix for your clustering labels and the ground truth for the samples that are labeled.\n","\n","Interpret the result by analyzing which types of activities each cluster contains. Note that if the matrix element $C_{i,j} = 8$, it means your model called 8 samples of category $j$ as being $i$."]},{"cell_type":"code","execution_count":181,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>Predicted</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","    </tr>\n","    <tr>\n","      <th>Actual</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1.0</th>\n","      <td>24</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>6</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2.0</th>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3.0</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>4</td>\n","      <td>18</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4.0</th>\n","      <td>0</td>\n","      <td>29</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>5.0</th>\n","      <td>0</td>\n","      <td>44</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6.0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>29</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["Predicted   0   1  2  3   4   5\n","Actual                         \n","1.0        24   0  4  2   6   0\n","2.0        20   0  0  5   3   0\n","3.0         2   0  6  4  18   0\n","4.0         0  29  0  0   0   2\n","5.0         0  44  0  0   0   0\n","6.0         1   1  0  0   0  29"]},"execution_count":181,"metadata":{},"output_type":"execute_result"}],"source":["perf = kmeans.labels_[0:200]\n","\n","confusion_matrix = pd.crosstab(y_train, perf, rownames=['Actual'], colnames=['Predicted'])\n","confusion_matrix"]},{"cell_type":"markdown","metadata":{},"source":["#### Adjusted Rand Score (ARS)"]},{"cell_type":"markdown","metadata":{},"source":["A common metric to evaluate if a clustering maps into some grouping is the adjusted Rand score. The Rand Index computes a similarity measure between two clusterings by considering all pairs of samples and counting pairs that are assigned in the same or different clusters in the predicted and true clusterings. The raw RI score is then adjusted for chance into the adjusted score.\n","\n","Calculate the ARS for the labeled samples, using `adjusted_rand_score()` in `sklearn`. This is the performance metric that will be used to test your predictions in the test set. A score over 0.5 is a good target. Can you do better?"]},{"cell_type":"code","execution_count":182,"metadata":{},"outputs":[{"data":{"text/plain":["0.5120853294433937"]},"execution_count":182,"metadata":{},"output_type":"execute_result"}],"source":["# Calculate adjusted rand score for clusters\n","from sklearn.metrics import adjusted_rand_score\n","\n","adjusted_rand_score(y_train, perf)"]},{"cell_type":"markdown","metadata":{},"source":["For comparison, run your clustering model directly on the raw time-series data `X_train` (without feature extraction and preprocessing) and check the performance."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["### Predict test set groups"]},{"cell_type":"markdown","metadata":{},"source":["Save the clustering labels for all samples in the variable `cluster_labels`. It will be evaluated against the ground-truth using the adjusted rand score."]},{"cell_type":"code","execution_count":183,"metadata":{},"outputs":[],"source":["cluster_labels = kmeans.labels_"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
